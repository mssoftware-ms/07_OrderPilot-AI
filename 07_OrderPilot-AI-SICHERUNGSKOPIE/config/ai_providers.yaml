# AI Provider Configuration
# Supports multiple AI providers with different models and reasoning modes

# Default provider to use
default_provider: "anthropic"
default_model: "sonnet_45"

# Provider configurations
providers:
  # OpenAI Configuration
  openai:
    # GPT-5.1 with Thinking (adaptive reasoning)
    gpt51_thinking:
      model: "gpt-5.1"
      max_tokens: 4096
      temperature: 0.2
      reasoning_mode: "medium"  # none, minimal, low, medium, high
      streaming: false
      use_cases:
        - "complex_analysis"
        - "backtest_review"
        - "risk_assessment"
        - "parameter_optimization"

    # GPT-5.1 Instant (no thinking, faster)
    gpt51_instant:
      model: "gpt-5.1-chat-latest"
      max_tokens: 2048
      temperature: 0.3
      reasoning_mode: "none"
      streaming: true
      use_cases:
        - "quick_queries"
        - "chat"
        - "simple_analysis"
        - "alerts"

    # GPT-4o (fallback)
    gpt4o:
      model: "gpt-4o"
      max_tokens: 4096
      temperature: 0.2
      reasoning_mode: "none"
      streaming: false
      use_cases:
        - "general_purpose"
        - "structured_outputs"

    # GPT-4o-mini (cost-effective)
    gpt4o_mini:
      model: "gpt-4o-mini"
      max_tokens: 2048
      temperature: 0.2
      reasoning_mode: "none"
      streaming: false
      use_cases:
        - "simple_tasks"
        - "quick_analysis"
        - "cost_conscious"

  # Anthropic Configuration
  anthropic:
    # Claude Sonnet 4.5 (most capable)
    sonnet_45:
      model: "claude-sonnet-4-5-20250929"
      max_tokens: 4096
      temperature: 0.2
      streaming: false
      use_cases:
        - "complex_reasoning"
        - "code_analysis"
        - "strategy_review"
        - "market_analysis"

    # Claude Sonnet 4.5 alias (always latest)
    sonnet_latest:
      model: "claude-sonnet-4-5"
      max_tokens: 4096
      temperature: 0.2
      streaming: false
      use_cases:
        - "complex_reasoning"
        - "long_context"

# Task-specific provider selection
task_routing:
  # Backtest review: Use Anthropic Sonnet 4.5 for deep analysis
  backtest_review:
    primary: "anthropic.sonnet_45"
    fallback: "openai.gpt51_thinking"
    reasoning_mode: "high"

  # Parameter optimization: Use Anthropic for complex reasoning
  parameter_optimization:
    primary: "anthropic.sonnet_45"
    fallback: "openai.gpt51_thinking"
    reasoning_mode: "medium"

  # Quick market analysis: Use fast models
  market_analysis:
    primary: "openai.gpt51_instant"
    fallback: "openai.gpt4o_mini"
    reasoning_mode: "none"

  # Alert triage: Fast decisions needed
  alert_triage:
    primary: "openai.gpt51_instant"
    fallback: "anthropic.sonnet_45"
    reasoning_mode: "minimal"

  # Order analysis: Balance speed and accuracy
  order_analysis:
    primary: "openai.gpt51_thinking"
    fallback: "anthropic.sonnet_45"
    reasoning_mode: "low"

  # Signal analysis: Anthropic excels at technical analysis
  signal_analysis:
    primary: "anthropic.sonnet_45"
    fallback: "openai.gpt51_instant"
    reasoning_mode: "medium"

  # Risk assessment: Anthropic for deep analysis
  risk_assessment:
    primary: "anthropic.sonnet_45"
    fallback: "openai.gpt51_thinking"
    reasoning_mode: "high"

  # Chat/Interactive: Fast responses
  chat:
    primary: "openai.gpt51_instant"
    fallback: "openai.gpt4o_mini"
    reasoning_mode: "none"
    streaming: true

# Cost management
cost_limits:
  daily_limit_eur: 10.0
  monthly_limit_eur: 100.0
  warn_threshold: 0.8  # Warn at 80% of limit

# Pricing per 1M tokens (EUR) - approximate as of 2025
pricing:
  openai:
    "gpt-5.1": {input: 3.00, output: 12.00}
    "gpt-5.1-chat-latest": {input: 2.50, output: 10.00}
    "gpt-4o": {input: 2.50, output: 10.00}
    "gpt-4o-mini": {input: 0.15, output: 0.60}
  anthropic:
    "claude-sonnet-4-5-20250929": {input: 3.00, output: 15.00}
    "claude-sonnet-4-5": {input: 3.00, output: 15.00}

# Retry configuration
retry:
  max_attempts: 3
  initial_delay_ms: 1000
  max_delay_ms: 10000
  exponential_base: 2

# Timeout configuration
timeouts:
  connect_ms: 5000
  read_ms: 30000
  total_ms: 60000

# Caching
cache:
  enabled: true
  ttl_seconds: 3600  # 1 hour
  max_size: 1000

# Logging
logging:
  log_requests: true
  log_responses: false  # Can be large
  log_costs: true
  log_latency: true

# Feature flags
features:
  streaming_enabled: true
  structured_outputs: true
  reasoning_modes: true
  multi_provider: true
  cost_tracking: true
  cache: true
