"""Bitunix Futures Historical Data Provider.

Provides historical kline (OHLCV) data from Bitunix Futures API
with HMAC-SHA256 authentication.
"""

import asyncio
import hashlib
import hmac
import logging
import time
from datetime import datetime, timezone
from decimal import Decimal

import aiohttp

from src.core.market_data.providers.base import HistoricalDataProvider
from src.core.market_data.types import HistoricalBar, Timeframe

logger = logging.getLogger(__name__)


class BitunixProvider(HistoricalDataProvider):
    """Bitunix Futures historical data provider.

    Fetches historical kline (candlestick) data from Bitunix Futures API.
    Supports Crypto Futures (Perpetual) contracts only.

    Authentication:
        Public market data endpoints (kline) do NOT require API keys.
        API keys are only needed for trading operations.

    Rate Limiting:
        Rate limit: 10 req/s per IP. Using 0.15s delay to stay safe.

    Endpoints:
        - Market Data (public): https://fapi.bitunix.com/api/v1/futures/market/kline
    """

    def __init__(
        self,
        api_key: str | None = None,
        api_secret: str | None = None,
        use_testnet: bool = False,
        enable_cache: bool = True,
        max_bars: int = 525600,  # 1 year of 1min bars
        max_batches: int = 3000,  # 525600 / 200 = 2628 batches for 1 year
    ):
        """Initialize Bitunix provider.

        Args:
            api_key: Bitunix API key (optional for public market data)
            api_secret: Bitunix API secret (optional for public market data)
            use_testnet: Use testnet environment (default: False for market data)
            enable_cache: Enable response caching
            max_bars: Safety cap for total bars fetched (default: 525600 = 1 year 1min)
            max_batches: Safety cap for request batches (default: 3000 for 1 year)
        """
        super().__init__("Bitunix Futures", enable_cache)
        self.api_key = api_key
        self.api_secret = api_secret
        self.use_testnet = use_testnet
        self.base_url = self._get_base_url()
        self.rate_limit_delay = 0.15  # 10 req/s limit â†’ 0.1s, use 0.15s to be safe
        self.max_bars = max_bars
        self.max_batches = max_batches

    def _get_base_url(self) -> str:
        """Get API base URL based on environment.

        Returns:
            Base URL for Bitunix API
        """
        # For Market Data, we prefer Mainnet to ensure realistic data (volume/liquidity)
        # even when in Testnet/Paper trading mode.
        # Verified URL from Python Demo: https://fapi.bitunix.com
        return "https://fapi.bitunix.com"

        # Previous Testnet URL (unverified/broken): https://testnet-api.bitunix.com
        # if self.use_testnet:
        #     return "https://testnet-api.bitunix.com"
        # return "https://fapi.bitunix.com"

    def _generate_signature(self, params: dict) -> str:
        """Generate HMAC-SHA256 signature for Bitunix API.

        The signature is generated by:
        1. Sorting parameters alphabetically by key
        2. Creating query string: key1=value1&key2=value2
        3. Computing HMAC-SHA256 with api_secret as key

        Args:
            params: Request parameters

        Returns:
            Hex-encoded signature string
        """
        # Sort parameters alphabetically
        sorted_params = sorted(params.items())
        query_string = "&".join([f"{k}={v}" for k, v in sorted_params])

        # Generate HMAC-SHA256 signature
        signature = hmac.new(
            self.api_secret.encode('utf-8'),
            query_string.encode('utf-8'),
            hashlib.sha256
        ).hexdigest()

        return signature

    def _build_headers(self, params: dict) -> dict:
        """Build request headers with API key and signature.

        For public market data endpoints (kline), no authentication is required.
        Only adds auth headers if API keys are provided.

        Args:
            params: Request parameters (may be modified with timestamp if auth)

        Returns:
            Headers dictionary for HTTP request
        """
        headers = {'Content-Type': 'application/json'}

        # Only add authentication if API keys are provided
        # Public market data endpoints don't require authentication
        if self.api_key and self.api_secret:
            # Add timestamp (required for signature)
            params['timestamp'] = int(time.time() * 1000)
            # Generate signature
            signature = self._generate_signature(params)
            headers['X-API-KEY'] = self.api_key
            headers['X-SIGNATURE'] = signature

        return headers

    def _timeframe_to_bitunix(self, tf: Timeframe) -> str:
        """Convert Timeframe enum to Bitunix interval string.

        Args:
            tf: Timeframe enum

        Returns:
            Bitunix interval string (e.g., '1m', '5m', '1h')
        """
        mapping = {
            Timeframe.MINUTE_1: "1m",
            Timeframe.MINUTE_5: "5m",
            Timeframe.MINUTE_15: "15m",
            Timeframe.MINUTE_30: "30m",
            Timeframe.HOUR_1: "1h",
            Timeframe.HOUR_4: "4h",
            Timeframe.DAY_1: "1d",
        }
        interval = mapping.get(tf)
        if not interval:
            logger.warning(f"Unsupported timeframe {tf}, defaulting to 1m")
            return "1m"
        return interval

    @staticmethod
    def _interval_ms(interval: str) -> int:
        """Return interval length in milliseconds for pagination."""
        table = {
            "1m": 60_000,
            "5m": 5 * 60_000,
            "15m": 15 * 60_000,
            "30m": 30 * 60_000,
            "1h": 60 * 60_000,
            "4h": 4 * 60 * 60_000,
            "1d": 24 * 60 * 60_000,
        }
        return table.get(interval, 60_000)

    async def fetch_bars(
        self,
        symbol: str,
        start_date: datetime,
        end_date: datetime,
        timeframe: Timeframe
    ) -> list[HistoricalBar]:
        """Fetch historical klines from Bitunix.

        Bitunix API returns data in DESCENDING order (newest first).
        We paginate backwards from end_date to start_date.

        Args:
            symbol: Trading symbol (e.g., 'BTCUSDT', 'ETHUSDT')
            start_date: Start date for data
            end_date: End date for data
            timeframe: Bar timeframe

        Returns:
            List of historical bars

        Raises:
            aiohttp.ClientError: On API request failures
        """
        interval = self._timeframe_to_bitunix(timeframe)
        interval_ms = self._interval_ms(interval)
        start_ms = int(start_date.timestamp() * 1000)
        current_end_ms = int(end_date.timestamp() * 1000)
        limit = 200  # API spec: max 200 per call

        all_bars: list[HistoricalBar] = []
        max_batches = self.max_batches or 120

        logger.info(f"ðŸ“¡ Bitunix Provider: Fetching {symbol} bars...")
        logger.info(f"ðŸ“¡ Bitunix Provider: Timeframe={timeframe.value}, Interval={interval}")
        logger.info(f"ðŸ“¡ Bitunix Provider: Start={start_date}, End={end_date}")
        logger.debug(f"ðŸ“¡ Bitunix Provider: Base URL={self.base_url}")

        try:
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=60)) as session:
                batches = 0
                # Paginate BACKWARDS: from end_date towards start_date
                while current_end_ms > start_ms and batches < max_batches:
                    params = {
                        'symbol': symbol,
                        'interval': interval,
                        'limit': limit,
                        'startTime': start_ms,
                        'endTime': current_end_ms,
                    }

                    # Build headers (no auth needed for public market data)
                    headers = self._build_headers(params)

                    if batches % 50 == 0:
                        logger.info(f"ðŸ“¡ Bitunix Provider: Batch #{batches + 1}, bars so far: {len(all_bars)}")
                    logger.debug(f"ðŸ“¡ Bitunix Provider: Request #{batches + 1}, endTime={current_end_ms}")

                    async with session.get(
                        f"{self.base_url}/api/v1/futures/market/kline",
                        params=params,
                        headers=headers,
                    ) as response:
                        if response.status != 200:
                            error_text = await response.text()
                            logger.error(f"âŒ Bitunix API Error:")
                            logger.error(f"   HTTP Status: {response.status}")
                            logger.error(f"   Symbol: {symbol}")
                            logger.error(f"   Interval: {interval}")
                            logger.error(f"   URL: {self.base_url}/api/v1/futures/market/kline")
                            logger.error(f"   Params: {params}")
                            logger.error(f"   Response: {error_text[:500]}")  # First 500 chars
                            break

                        data = await response.json()

                        # Check for API-level errors (code != 0)
                        if data.get('code') != 0:
                            logger.error(f"âŒ Bitunix API Error Response:")
                            logger.error(f"   Error Code: {data.get('code')}")
                            logger.error(f"   Error Message: {data.get('msg', data.get('message', 'Unknown'))}")
                            logger.error(f"   Symbol: {symbol}")
                            logger.error(f"   Full Response: {data}")
                            break

                        # Parse klines (returns sorted ascending)
                        batch = self._parse_klines(data, symbol)

                        if not batch:
                            logger.info("No more bars returned; stopping pagination.")
                            break

                        all_bars.extend(batch)
                        if len(all_bars) >= self.max_bars:
                            logger.warning(
                                f"Reached max_bars={self.max_bars} for {symbol}; stopping pagination"
                            )
                            break

                        # IMPORTANT: Bitunix returns data in DESCENDING order (newest first)
                        # After sorting ascending, batch[0] is the OLDEST bar
                        # Next request: end_ms = oldest_timestamp - 1ms (go further back in time)
                        oldest_ts_ms = int(batch[0].timestamp.timestamp() * 1000)
                        current_end_ms = oldest_ts_ms - 1  # Move endTime backwards

                        batches += 1
                        if batches >= max_batches:
                            logger.warning(
                                f"Reached max_batches={max_batches} for {symbol}; stopping pagination"
                            )
                            break

                        # Respect rate limits (10 req/s)
                        await asyncio.sleep(self.rate_limit_delay)

            # Deduplicate and sort
            dedup = {int(bar.timestamp.timestamp() * 1000): bar for bar in all_bars}
            bars_sorted = [dedup[k] for k in sorted(dedup.keys())]

            logger.info(f"âœ… Bitunix Provider: Fetched {len(bars_sorted)} bars for {symbol} ({batches} requests, interval {interval})")
            return bars_sorted

        except asyncio.TimeoutError:
            logger.error(f"âŒ Bitunix Provider: Request timeout")
            logger.error(f"   Symbol: {symbol}")
            logger.error(f"   Interval: {interval}")
            logger.error(f"   URL: {self.base_url}/api/v1/futures/market/kline")
            logger.error(f"   Timeout: 30 seconds")
            return []
        except aiohttp.ClientError as e:
            logger.error(f"âŒ Bitunix Provider: Network error")
            logger.error(f"   Symbol: {symbol}")
            logger.error(f"   Error Type: {type(e).__name__}")
            logger.error(f"   Error: {e}")
            return []
        except Exception as e:
            logger.error(f"âŒ Bitunix Provider: Unexpected error")
            logger.error(f"   Symbol: {symbol}")
            logger.error(f"   Error Type: {type(e).__name__}")
            logger.error(f"   Error: {e}", exc_info=True)
            return []

    def _parse_klines(self, data: dict, symbol: str) -> list[HistoricalBar]:
        """Parse Bitunix kline response to HistoricalBar list.

        Expected response format:
        {
            "code": 0,
            "message": "success",
            "data": [
                {
                    "time": 1609459200000,
                    "open": "29000.0",
                    "high": "29500.0",
                    "low": "28800.0",
                    "close": "29300.0",
                    "baseVol": "123.45",
                    "quoteVol": "3600000.0"
                },
                ...
            ]
        }

        Args:
            data: API response JSON
            symbol: Trading symbol for logging

        Returns:
            List of HistoricalBar objects
        """
        bars = []

        # Check for API errors
        if data.get('code') != 0:
            logger.error(f"âŒ Bitunix Provider: API Error in kline response")
            logger.error(f"   Symbol: {symbol}")
            logger.error(f"   Error Code: {data.get('code')}")
            logger.error(f"   Error Message: {data.get('message', 'Unknown error')}")
            logger.error(f"   Full Response: {data}")
            return []

        klines = data.get('data', [])
        if not klines:
            logger.warning(f"âš ï¸ Bitunix Provider: No kline data in response")
            logger.warning(f"   Symbol: {symbol}")
            logger.warning(f"   Response Code: {data.get('code')}")
            logger.warning(f"   Full Response: {data}")
            return []

        for kline in klines:
            try:
                # Bitunix returns time as string or int in milliseconds
                ts_ms = int(kline['time'])

                bar = HistoricalBar(
                    timestamp=datetime.fromtimestamp(ts_ms / 1000, tz=timezone.utc),
                    open=Decimal(str(kline['open'])),
                    high=Decimal(str(kline['high'])),
                    low=Decimal(str(kline['low'])),
                    close=Decimal(str(kline['close'])),
                    volume=int(float(kline['baseVol'])),  # Base asset volume
                    source="bitunix"
                )
                bars.append(bar)
            except (KeyError, ValueError, TypeError) as e:
                logger.warning(f"Skipping invalid kline: {e} | Data: {kline}")
                continue

        # IMPORTANT: Sort bars by timestamp (ascending order)
        # Bitunix API may return bars in descending order, but charts expect ascending
        bars.sort(key=lambda b: b.timestamp)

        return bars

    async def is_available(self) -> bool:
        """Check if Bitunix provider is available.

        For public market data (kline), no API keys are required.
        Always returns True as the public endpoint is accessible.

        Returns:
            True (public market data is always available)
        """
        return True
