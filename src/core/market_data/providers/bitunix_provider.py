"""Bitunix Futures Historical Data Provider.

Provides historical kline (OHLCV) data from Bitunix Futures API
with HMAC-SHA256 authentication.
"""

import asyncio
import hashlib
import hmac
import logging
import time
from datetime import datetime, timezone
from decimal import Decimal

import aiohttp

from src.core.market_data.providers.base import HistoricalDataProvider
from src.core.market_data.types import HistoricalBar, Timeframe

logger = logging.getLogger(__name__)


class BitunixProvider(HistoricalDataProvider):
    """Bitunix Futures historical data provider.

    Fetches historical kline (candlestick) data from Bitunix Futures API.
    Supports Crypto Futures (Perpetual) contracts only.

    Authentication:
        Uses HMAC-SHA256 signature for API requests.

    Rate Limiting:
        Conservative 0.1s delay (~600 calls/min) to avoid rate limits.

    Environments:
        - Testnet: https://testnet-api.bitunix.com (default)
        - Mainnet: https://api.bitunix.com
    """

    def __init__(
        self,
        api_key: str,
        api_secret: str,
        use_testnet: bool = True,
        enable_cache: bool = True,
        max_bars: int = 15000,
        max_batches: int = 120,
    ):
        """Initialize Bitunix provider.

        Args:
            api_key: Bitunix API key
            api_secret: Bitunix API secret
            use_testnet: Use testnet environment (default: True for safety)
            enable_cache: Enable response caching
            max_bars: Safety cap for total bars fetched in one request sequence
            max_batches: Safety cap for request batches (pagination)
        """
        super().__init__("Bitunix Futures", enable_cache)
        self.api_key = api_key
        self.api_secret = api_secret
        self.use_testnet = use_testnet
        self.base_url = self._get_base_url()
        self.rate_limit_delay = 0.1  # Conservative: ~600 calls/min
        self.max_bars = max_bars
        self.max_batches = max_batches

    def _get_base_url(self) -> str:
        """Get API base URL based on environment.

        Returns:
            Base URL for Bitunix API
        """
        # For Market Data, we prefer Mainnet to ensure realistic data (volume/liquidity)
        # even when in Testnet/Paper trading mode.
        # Verified URL from Python Demo: https://fapi.bitunix.com
        return "https://fapi.bitunix.com"

        # Previous Testnet URL (unverified/broken): https://testnet-api.bitunix.com
        # if self.use_testnet:
        #     return "https://testnet-api.bitunix.com"
        # return "https://fapi.bitunix.com"

    def _generate_signature(self, params: dict) -> str:
        """Generate HMAC-SHA256 signature for Bitunix API.

        The signature is generated by:
        1. Sorting parameters alphabetically by key
        2. Creating query string: key1=value1&key2=value2
        3. Computing HMAC-SHA256 with api_secret as key

        Args:
            params: Request parameters

        Returns:
            Hex-encoded signature string
        """
        # Sort parameters alphabetically
        sorted_params = sorted(params.items())
        query_string = "&".join([f"{k}={v}" for k, v in sorted_params])

        # Generate HMAC-SHA256 signature
        signature = hmac.new(
            self.api_secret.encode('utf-8'),
            query_string.encode('utf-8'),
            hashlib.sha256
        ).hexdigest()

        return signature

    def _build_headers(self, params: dict) -> dict:
        """Build request headers with API key and signature.

        Adds timestamp to params and generates signature.

        Args:
            params: Request parameters (will be modified with timestamp)

        Returns:
            Headers dictionary for HTTP request
        """
        # Add timestamp (required for signature)
        params['timestamp'] = int(time.time() * 1000)

        # Generate signature
        signature = self._generate_signature(params)

        return {
            'X-API-KEY': self.api_key,
            'X-SIGNATURE': signature,
            'Content-Type': 'application/json'
        }

    def _timeframe_to_bitunix(self, tf: Timeframe) -> str:
        """Convert Timeframe enum to Bitunix interval string.

        Args:
            tf: Timeframe enum

        Returns:
            Bitunix interval string (e.g., '1m', '5m', '1h')
        """
        mapping = {
            Timeframe.MINUTE_1: "1m",
            Timeframe.MINUTE_5: "5m",
            Timeframe.MINUTE_15: "15m",
            Timeframe.MINUTE_30: "30m",
            Timeframe.HOUR_1: "1h",
            Timeframe.HOUR_4: "4h",
            Timeframe.DAY_1: "1d",
        }
        interval = mapping.get(tf)
        if not interval:
            logger.warning(f"Unsupported timeframe {tf}, defaulting to 1m")
            return "1m"
        return interval

    @staticmethod
    def _interval_ms(interval: str) -> int:
        """Return interval length in milliseconds for pagination."""
        table = {
            "1m": 60_000,
            "5m": 5 * 60_000,
            "15m": 15 * 60_000,
            "30m": 30 * 60_000,
            "1h": 60 * 60_000,
            "4h": 4 * 60 * 60_000,
            "1d": 24 * 60 * 60_000,
        }
        return table.get(interval, 60_000)

    async def fetch_bars(
        self,
        symbol: str,
        start_date: datetime,
        end_date: datetime,
        timeframe: Timeframe
    ) -> list[HistoricalBar]:
        """Fetch historical klines from Bitunix.

        Args:
            symbol: Trading symbol (e.g., 'BTCUSDT', 'ETHUSDT')
            start_date: Start date for data
            end_date: End date for data
            timeframe: Bar timeframe

        Returns:
            List of historical bars

        Raises:
            aiohttp.ClientError: On API request failures
        """
        interval = self._timeframe_to_bitunix(timeframe)
        interval_ms = self._interval_ms(interval)
        start_ms = int(start_date.timestamp() * 1000)
        end_ms = int(end_date.timestamp() * 1000)
        limit = 200  # API spec: max 200 per call

        headers = {'Content-Type': 'application/json'}
        all_bars: list[HistoricalBar] = []
        max_batches = self.max_batches or 120

        try:
            async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=30)) as session:
                batches = 0
                while start_ms < end_ms and batches < max_batches:
                    params = {
                        'symbol': symbol,
                        'interval': interval,
                        'limit': limit,
                        'startTime': start_ms,
                        'endTime': end_ms,
                        'type': 'LAST_PRICE',
                    }

                    async with session.get(
                        f"{self.base_url}/api/v1/futures/market/kline",
                        params=params,
                        headers=headers,
                    ) as response:
                        if response.status != 200:
                            error_text = await response.text()
                            logger.error(f"Bitunix API error {response.status}: {error_text}")
                            break

                        data = await response.json()
                        batch = self._parse_klines(data, symbol)

                        if not batch:
                            logger.info("No more bars returned; stopping pagination.")
                            break

                        all_bars.extend(batch)
                        if len(all_bars) >= self.max_bars:
                            logger.warning(
                                f"Reached max_bars={self.max_bars} for {symbol}; stopping pagination"
                            )
                            break

                        # Advance window: next start = last bar timestamp + interval
                        last_ts_ms = int(batch[-1].timestamp.timestamp() * 1000)
                        start_ms = last_ts_ms + interval_ms
                        batches += 1
                        if batches >= max_batches:
                            logger.warning(
                                f"Reached max_batches={max_batches} for {symbol}; stopping pagination"
                            )
                            break

                        # Respect rate limits
                        await asyncio.sleep(self.rate_limit_delay)

            # Deduplicate and sort
            dedup = {int(bar.timestamp.timestamp() * 1000): bar for bar in all_bars}
            bars_sorted = [dedup[k] for k in sorted(dedup.keys())]

            logger.info(f"Fetched {len(bars_sorted)} bars for {symbol} from {self.name} ({batches} requests, interval {interval})")
            return bars_sorted

        except asyncio.TimeoutError:
            logger.error(f"Timeout fetching {symbol} from {self.name}")
            return []
        except aiohttp.ClientError as e:
            logger.error(f"Network error fetching {symbol}: {e}")
            return []
        except Exception as e:
            logger.error(f"Unexpected error fetching {symbol}: {e}")
            return []

    def _parse_klines(self, data: dict, symbol: str) -> list[HistoricalBar]:
        """Parse Bitunix kline response to HistoricalBar list.

        Expected response format:
        {
            "code": 0,
            "message": "success",
            "data": [
                {
                    "time": 1609459200000,
                    "open": "29000.0",
                    "high": "29500.0",
                    "low": "28800.0",
                    "close": "29300.0",
                    "baseVol": "123.45",
                    "quoteVol": "3600000.0"
                },
                ...
            ]
        }

        Args:
            data: API response JSON
            symbol: Trading symbol for logging

        Returns:
            List of HistoricalBar objects
        """
        bars = []

        # Check for API errors
        if data.get('code') != 0:
            logger.error(
                f"Bitunix API returned error code {data.get('code')}: "
                f"{data.get('message', 'Unknown error')}"
            )
            return []

        klines = data.get('data', [])
        if not klines:
            logger.warning(f"No kline data returned for {symbol}. Full response: {data}")
            return []

        for kline in klines:
            try:
                # Bitunix returns time as string or int in milliseconds
                ts_ms = int(kline['time'])

                bar = HistoricalBar(
                    timestamp=datetime.fromtimestamp(ts_ms / 1000, tz=timezone.utc),
                    open=Decimal(str(kline['open'])),
                    high=Decimal(str(kline['high'])),
                    low=Decimal(str(kline['low'])),
                    close=Decimal(str(kline['close'])),
                    volume=int(float(kline['baseVol'])),  # Base asset volume
                    source="bitunix"
                )
                bars.append(bar)
            except (KeyError, ValueError, TypeError) as e:
                logger.warning(f"Skipping invalid kline: {e} | Data: {kline}")
                continue

        # IMPORTANT: Sort bars by timestamp (ascending order)
        # Bitunix API may return bars in descending order, but charts expect ascending
        bars.sort(key=lambda b: b.timestamp)

        return bars

    async def is_available(self) -> bool:
        """Check if Bitunix provider is available.

        Verifies that API credentials are configured.
        Does NOT make an API call (use minimal resources).

        Returns:
            True if API key and secret are configured
        """
        return bool(self.api_key and self.api_secret)
